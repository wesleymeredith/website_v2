(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[652],{160:(e,i,r)=>{(window.__NEXT_P=window.__NEXT_P||[]).push(["/projects/HousingPriceContent",function(){return r(9423)}])},1131:(e,i,r)=>{"use strict";r.d(i,{A:()=>t});let t=(0,r(8614).A)("Github",[["path",{d:"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4",key:"tonef"}],["path",{d:"M9 18c-4.51 2-5-2-7-2",key:"9comsn"}]])},4822:(e,i,r)=>{"use strict";r.d(i,{A:()=>t});let t=(0,r(8614).A)("Play",[["polygon",{points:"5 3 19 12 5 21 5 3",key:"191637"}]])},5390:(e,i,r)=>{"use strict";r.d(i,{A:()=>t});let t=(0,r(8614).A)("FileText",[["path",{d:"M14.5 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V7.5L14.5 2z",key:"1nnpy2"}],["polyline",{points:"14 2 14 8 20 8",key:"1ew0cm"}],["line",{x1:"16",x2:"8",y1:"13",y2:"13",key:"14keom"}],["line",{x1:"16",x2:"8",y1:"17",y2:"17",key:"17nazh"}],["line",{x1:"10",x2:"8",y1:"9",y2:"9",key:"1a5vjj"}]])},8614:(e,i,r)=>{"use strict";r.d(i,{A:()=>a});var t=r(4232),s={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let a=(e,i)=>{let r=(0,t.forwardRef)((r,a)=>{let{color:n="currentColor",size:l=24,strokeWidth:o=2,absoluteStrokeWidth:c,className:m="",children:d,...h}=r;return(0,t.createElement)("svg",{ref:a,...s,width:l,height:l,stroke:n,strokeWidth:c?24*Number(o)/Number(l):o,className:["lucide","lucide-".concat(e.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase().trim()),m].join(" "),...h},[...i.map(e=>{let[i,r]=e;return(0,t.createElement)(i,r)}),...Array.isArray(d)?d:[d]])});return r.displayName="".concat(e),r}},9423:(e,i,r)=>{"use strict";r.r(i),r.d(i,{__N_SSG:()=>c,default:()=>m});var t=r(7876);r(4232);var s=r(1131),a=r(4822),n=r(5390);let l=e=>{let{project:i}=e;return(0,t.jsxs)("div",{className:"space-y-4 mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-semibold tracking-tight mb-6",children:"Project Links"}),(0,t.jsxs)("div",{className:"flex flex-wrap gap-4",children:[(null==i?void 0:i.github)&&(0,t.jsxs)("a",{href:i.github,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center px-6 py-3 bg-gray-900 text-white font-medium rounded-lg hover:bg-gray-800 transition-colors duration-200",children:[(0,t.jsx)(s.A,{size:20,className:"mr-2"}),"View Code"]}),(null==i?void 0:i.demo)&&(0,t.jsxs)("a",{href:i.demo,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center px-6 py-3 bg-blue-600 text-white font-medium rounded-lg hover:bg-blue-700 transition-colors duration-200",children:[(0,t.jsx)(a.A,{size:20,className:"mr-2"}),"Live Demo"]}),(null==i?void 0:i.notebook)&&(0,t.jsxs)("a",{href:i.notebook,target:"_blank",rel:"noopener noreferrer",className:"inline-flex items-center px-6 py-3 bg-green-600 text-white font-medium rounded-lg hover:bg-green-700 transition-colors duration-200",children:[(0,t.jsx)(n.A,{size:20,className:"mr-2"}),"View Notebook"]})]})]})},o=e=>{let{project:i}=e;return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(l,{project:i}),(0,t.jsxs)("div",{className:"mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-semibold tracking-tight mb-6",children:"Introduction"}),(0,t.jsx)("div",{className:"prose prose-lg mb-12",children:(0,t.jsx)("p",{className:"mb-6",children:"This study focused on predicting housing prices using the Ames Housing dataset, comparing four different machine learning approaches: Decision Tree, Random Forest, XGBoost, and Artificial Neural Networks (ANN). The project particularly investigated whether feature engineering or hyperparameter tuning had a greater impact on model performance."})})]}),(0,t.jsxs)("div",{className:"mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-semibold tracking-tight mb-6",children:"Dataset"}),(0,t.jsx)("div",{className:"prose prose-lg mb-12",children:(0,t.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,t.jsx)("li",{children:"Training Set: 1,460 samples"}),(0,t.jsx)("li",{children:"Testing Set: 1,459 samples"}),(0,t.jsx)("li",{children:"Features: 79 property attributes (both numerical and categorical)"}),(0,t.jsx)("li",{children:"Target Variable: Sale Price"})]})})]}),(0,t.jsxs)("div",{className:"mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-semibold tracking-tight mb-6",children:"Methodology"}),(0,t.jsxs)("div",{className:"prose prose-lg mb-12",children:[(0,t.jsx)("h4",{className:"mt-4 mb-1 font-semibold text-gray-800",children:"Data Preprocessing"}),(0,t.jsx)("p",{className:"mb-6",children:"Our preprocessing pipeline began with thorough missing value treatment. For categorical data, we imputed missing values with ‘None’, while numerical missing values were filled using mean or median values as appropriate. We then applied label encoding to convert categorical variables into a format suitable for our models."}),(0,t.jsx)("h4",{className:"mt-4 mb-1 font-semibold text-gray-800",children:"Feature Engineering"}),(0,t.jsx)("p",{className:"mb-6",children:"The feature engineering process involved creating several new meaningful features. We developed polynomial features for key metrics like square footage and room numbers, created interaction features combining variables like age and size, and generated ratio features such as living area to lot size ratio. These efforts significantly improved our model’s predictive power, raising the average Mutual Information score from 0.126 to 0.162."}),(0,t.jsx)("h4",{className:"mt-4 mb-1 font-semibold text-gray-800",children:"Model Implementation"}),(0,t.jsx)("p",{className:"mb-6",children:"We implemented a comprehensive evaluation framework testing each model against various preprocessing techniques. Starting with baseline implementations, we explored PCA dimensionality reduction, feature selection, outlier removal, feature engineering, and hyperparameter tuning to understand their relative impact on model performance."})]})]}),(0,t.jsxs)("div",{className:"mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-semibold tracking-tight mb-6",children:"Results"}),(0,t.jsxs)("div",{className:"prose prose-lg mb-12",children:[(0,t.jsx)("h4",{className:"mt-4 mb-1 font-semibold text-gray-800",children:"Model Performance Comparison"}),(0,t.jsx)("p",{className:"mb-6",children:"Best RMSE scores for each model after feature engineering:"}),(0,t.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,t.jsx)("li",{children:"Decision Tree: 32,542"}),(0,t.jsx)("li",{children:"Random Forest: 27,590"}),(0,t.jsx)("li",{children:"XGBoost: 26,598"}),(0,t.jsx)("li",{children:"ANN: 21,776"})]}),(0,t.jsx)("h4",{className:"mt-4 mb-1 font-semibold text-gray-800",children:"Key Insights"}),(0,t.jsx)("p",{className:"mb-6",children:"The feature engineering process proved to be the most impactful factor in improving model performance, reducing RMSE by approximately 15–30% across all models while enhancing interpretability. PCA, contrary to expectations, showed poor improvements across all models, largely because PCA conflicts with the non-linear relationships in the housing dataset."}),(0,t.jsx)("p",{className:"mb-6",children:"Our ANN implementation saw significant gains from architectural optimization. The three-layer design (128/64/32 neurons) with L2 Regularization and ReLU activations proved most effective. Interestingly, hyperparameter tuning showed minimal impact compared to feature engineering, suggesting that architecture and data quality mattered more than parameter optimization here."})]})]}),(0,t.jsxs)("div",{className:"mb-12",children:[(0,t.jsx)("h2",{className:"text-3xl font-semibold tracking-tight mb-6",children:"Final Thoughts / Future Work"}),(0,t.jsxs)("div",{className:"prose prose-lg mb-12",children:[(0,t.jsx)("p",{className:"mb-6",children:"This was my first end-to-end data science project. The biggest takeaway was how crucial data cleaning and transformation are. If I revisit this project, I’ll experiment with ensembling approaches and put more emphasis on EDA."}),(0,t.jsx)("br",{}),(0,t.jsx)("p",{className:"mb-6",children:(0,t.jsx)("em",{children:"This project was completed in collaboration with Kaijun Zhang and Yiran Zhu at North Carolina State University."})})]})]})]})};var c=!0;function m(e){let{project:i}=e;return(0,t.jsx)(o,{project:i})}}},e=>{e.O(0,[636,593,792],()=>e(e.s=160)),_N_E=e.O()}]);