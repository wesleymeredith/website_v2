<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8" data-next-head=""/><title data-next-head="">Housing Price Prediction Challenge - Project</title><meta name="description" content="Secured a top 12% ranking on Kaggle&#x27;s housing price prediction challenge by applying machine learning algorithms, feature engineering, and hyperparameter tuning techniques." data-next-head=""/><meta name="viewport" content="width=device-width, initial-scale=1" data-next-head=""/><link rel="icon" href="images/favicon.ico" data-next-head=""/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="icon" href="/images/favicon.ico"/><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png"/><meta name="theme-color" content="#ffffff"/><meta name="robots" content="index, follow"/><meta property="og:type" content="website"/><meta property="og:site_name" content="Data Scientist Portfolio"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@yourusername"/><link rel="preload" href="/_next/static/css/85a907efbd0c0b5e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/85a907efbd0c0b5e.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-22e55b39fad5ed53.js" defer=""></script><script src="/_next/static/chunks/framework-f75312fc4004b783.js" defer=""></script><script src="/_next/static/chunks/main-1559bd253066fbd1.js" defer=""></script><script src="/_next/static/chunks/pages/_app-48e49d6afe408d10.js" defer=""></script><script src="/_next/static/chunks/535-50c42ac52f115fb6.js" defer=""></script><script src="/_next/static/chunks/809-0288ddbe766f6f6f.js" defer=""></script><script src="/_next/static/chunks/pages/projects/%5Bid%5D-e7ee4cea1e2bd01f.js" defer=""></script><script src="/_next/static/by-NR_V2GyUIWaaFDTl5G/_buildManifest.js" defer=""></script><script src="/_next/static/by-NR_V2GyUIWaaFDTl5G/_ssgManifest.js" defer=""></script></head><body><div id="__next"><main class="min-h-screen bg-white"><div class="pt-16 px-4 sm:px-6 lg:px-8"><div class="max-w-4xl mx-auto"><div class="mb-12"><h1 class="text-4xl sm:text-5xl font-bold text-gray-900 mb-4">Housing Price Prediction Challenge</h1><p class="text-lg text-gray-600 mb-6">Wesley Meredith<!-- --> • <!-- -->2023</p></div><div class="mb-12"><img src="/images/projects/StockNewsCover.png" alt="Housing Price Prediction Challenge" class="w-full rounded-lg shadow-lg"/></div><div class="space-y-4 mb-12"><h2 class="text-3xl font-semibold tracking-tight mb-6">Project Links</h2><div class="flex flex-wrap gap-4"><a href="https://github.com/wesleymeredith/Ames-Housing-Project" target="_blank" rel="noopener noreferrer" class="inline-flex items-center px-6 py-3 bg-gray-900 text-white font-medium rounded-lg hover:bg-gray-800 transition-colors duration-200"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github mr-2"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>View Code</a></div></div><div class="mb-12"><h2 class="text-3xl font-semibold tracking-tight mb-6">Introduction</h2><div class="prose prose-lg mb-12"><p class="mb-6">This study focused on predicting housing prices using the Ames Housing dataset, comparing four different machine learning approaches: Decision Tree, Random Forest, XGBoost, and Artificial Neural Networks (ANN). The project particularly investigated whether feature engineering or hyperparameter tuning had a greater impact on model performance.</p></div></div><div class="mb-12"><h2 class="text-3xl font-semibold tracking-tight mb-6">Dataset</h2><div class="prose prose-lg mb-12"><ul class="list-disc list-inside mb-6"><li>Training Set: 1,460 samples</li><li>Testing Set: 1,459 samples</li><li>Features: 79 property attributes (both numerical and categorical)</li><li>Target Variable: Sale Price</li></ul></div></div><div class="mb-12"><h2 class="text-3xl font-semibold tracking-tight mb-6">Methodology</h2><div class="prose prose-lg mb-12"><h4 class="mt-4 mb-1 font-semibold text-gray-800">Data Preprocessing</h4><p class="mb-6">Our preprocessing pipeline began with thorough missing value treatment. For categorical data, we imputed missing values with ‘None’, while numerical missing values were filled using mean or median values as appropriate. We then applied label encoding to convert categorical variables into a format suitable for our models.</p><h4 class="mt-4 mb-1 font-semibold text-gray-800">Feature Engineering</h4><p class="mb-6">The feature engineering process involved creating several new meaningful features. We developed polynomial features for key metrics like square footage and room numbers, created interaction features combining variables like age and size, and generated ratio features such as living area to lot size ratio. These efforts significantly improved our model’s predictive power, raising the average Mutual Information score from 0.126 to 0.162.</p><h4 class="mt-4 mb-1 font-semibold text-gray-800">Model Implementation</h4><p class="mb-6">We implemented a comprehensive evaluation framework testing each model against various preprocessing techniques. Starting with baseline implementations, we explored PCA dimensionality reduction, feature selection, outlier removal, feature engineering, and hyperparameter tuning to understand their relative impact on model performance.</p></div></div><div class="mb-12"><h2 class="text-3xl font-semibold tracking-tight mb-6">Results</h2><div class="prose prose-lg mb-12"><h4 class="mt-4 mb-1 font-semibold text-gray-800">Model Performance Comparison</h4><p class="mb-6">Best RMSE scores for each model after feature engineering:</p><ul class="list-disc list-inside mb-6"><li>Decision Tree: 32,542</li><li>Random Forest: 27,590</li><li>XGBoost: 26,598</li><li>ANN: 21,776</li></ul><h4 class="mt-4 mb-1 font-semibold text-gray-800">Key Insights</h4><p class="mb-6">The feature engineering process proved to be the most impactful factor in improving model performance, reducing RMSE by approximately 15–30% across all models while enhancing interpretability. PCA, contrary to expectations, showed poor improvements across all models, largely because PCA conflicts with the non-linear relationships in the housing dataset.</p><p class="mb-6">Our ANN implementation saw significant gains from architectural optimization. The three-layer design (128/64/32 neurons) with L2 Regularization and ReLU activations proved most effective. Interestingly, hyperparameter tuning showed minimal impact compared to feature engineering, suggesting that architecture and data quality mattered more than parameter optimization here.</p></div></div><div class="mb-12"><h2 class="text-3xl font-semibold tracking-tight mb-6">Final Thoughts / Future Work</h2><div class="prose prose-lg mb-12"><p class="mb-6">This was my first end-to-end data science project. The biggest takeaway was how crucial data cleaning and transformation are. If I revisit this project, I’ll experiment with ensembling approaches and put more emphasis on EDA.</p><br/><p class="mb-6"><em>This project was completed in collaboration with Kaijun Zhang and Yiran Zhu at North Carolina State University.</em></p></div></div><div class="pt-8 border-gray-200"><button class="inline-flex items-center text-gray-600 hover:text-gray-900 transition-colors duration-200"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left mr-2"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg>Back to Projects</button></div></div></div></main><footer class="bg-white text-gray-900 py-8 border-t border-gray-200"><div class="max-w-6xl mx-auto px-4 sm:px-6 lg:px-8"><div class="flex flex-col md:flex-row items-center justify-between"><div class="mb-4 md:mb-0"><p class="text-gray-600 text-sm">© <!-- -->2025<!-- --> Wesley Meredith. All rights reserved.</p></div><div class="flex space-x-6"><a href="#hero" class="text-gray-600 hover:text-gray-900 text-sm transition-colors duration-200">Back to Top</a><a href="#contact" class="text-gray-600 hover:text-gray-900 text-sm transition-colors duration-200">Contact</a></div></div></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"id":"housing-price-prediction"},"__N_SSG":true},"page":"/projects/[id]","query":{"id":"housing-price-prediction"},"buildId":"by-NR_V2GyUIWaaFDTl5G","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>